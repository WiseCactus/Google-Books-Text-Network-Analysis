{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.8/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# These are the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2pdf\n",
      "  Downloading docx2pdf-0.1.7-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: appscript<2.0.0,>=1.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from docx2pdf) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.8/site-packages (from docx2pdf) (4.50.2)\n",
      "Installing collected packages: docx2pdf\n",
      "Successfully installed docx2pdf-0.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docx2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasXpath(xpath):\n",
    "    try:\n",
    "        #driver.find_element_by_xpath(xpath)\n",
    "        driver.find_element_by_css_selector(xpath)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def hasClass(xpath):\n",
    "    try:\n",
    "        #driver.find_element_by_xpath(xpath)\n",
    "        driver.find_element_by_class_name(xpath)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "import urllib\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from docx import Document\n",
    "\n",
    "# Enter the search here.\n",
    "\n",
    "counter=0\n",
    "driver = selenium.webdriver.Firefox(executable_path=\"/Users/Camille/Downloads/geckodriver\")\n",
    "driver.get(\"https://www.google.ca/books/edition/The_Nomenclature_and_Expositor_of_the_En/xpoRAAAAIAAJ?hl=en&gbpv=1&dq=ble&pg=PA79&printsec=frontcover\")\n",
    "driver.switch_to.frame(\"s7Z8Jb\")\n",
    "driver.find_element_by_css_selector('span.search-bar-link:nth-child(6)').click()\n",
    "driver.execute_script(\"arguments[0].style.transform='scale(2.15)';\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "#driver.execute_script(\"arguments[0].scrollTo(0, 0)\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "#driver.find_element_by_class_name(\"overflow-scrolling\").send_keys(Keys.CONTROL + Keys.HOME)\n",
    "driver.execute_script(\"arguments[0].scrollBy(0, 70)\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "driver.execute_script(\"arguments[0].scrollBy(0, 70)\",driver.find_element_by_class_name(\"overflow-scrolling\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb300916849a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    228\u001b[0m                         \u001b[0;31m# Give the program some time to load the book.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                         \u001b[0;31m# We save the screenshots and crop them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test clicking the different pages:\n",
    "import requests\n",
    "from PIL import Image\n",
    "import selenium\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "import urllib\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from docx import Document\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "\n",
    "driver = selenium.webdriver.Firefox(executable_path=\"/Users/Camille/Downloads/geckodriver\")\n",
    "\n",
    "driver.get(\"https://www.google.com/search?tbm=bks&q=truth\")\n",
    "\n",
    "\n",
    "decade_count = 0\n",
    "\n",
    "# get a list of the books in order to check if any of the words match, and then delete those.\n",
    "\n",
    "decade_list = []\n",
    "\n",
    "t = (1800)\n",
    "start = str(t)\n",
    "year2 = 1930\n",
    "c = t + 10\n",
    "curr_year = str(c)\n",
    "\n",
    "decade_list.append(c)\n",
    "\n",
    "\n",
    "# This loop is created to iterate through each decade.\n",
    "\n",
    "# At the bottom of the loop, the current year will be incremented by 10 years.\n",
    "\n",
    "while year2!=curr_year:\n",
    "    \n",
    "    \n",
    "    # This segment retrieves the selected dates.\n",
    "\n",
    "    c=0\n",
    "    book_name = []\n",
    "    screen_shot_break = []\n",
    "\n",
    "    sleep(2)   \n",
    "\n",
    "    # Here the program selects the preview and full-text option.\n",
    "    \n",
    "    view = driver.find_elements_by_class_name(\"KTBKoe\")[0]\n",
    "    view.click()\n",
    "\n",
    "    # Here the program selects the respective timeline.\n",
    "    \n",
    "    driver.find_element_by_css_selector(\"div.EwsJzb:nth-child(1) > g-menu:nth-child(1) > g-menu-item:nth-child(2) > div:nth-child(1) > a:nth-child(1)\").click()\n",
    "    date=driver.find_elements_by_class_name(\"KTBKoe\")[2]\n",
    "\n",
    "    date.click()\n",
    "\n",
    "    # Here the program enters the timeframe which we are looking for.\n",
    "    \n",
    "    custom = driver.find_element_by_css_selector(\"div.EwsJzb:nth-child(1) > g-menu:nth-child(1) > g-menu-item:nth-child(5) > div:nth-child(1) > div:nth-child(1) > span:nth-child(1)\")\n",
    "    custom.click()\n",
    "    \n",
    "    driver.find_element_by_css_selector(\"#OouJcb\").send_keys(start)\n",
    "    driver.find_element_by_css_selector(\"#rzG2be\").send_keys(curr_year)\n",
    "    driver.find_element_by_css_selector(\".Ru1Ao\").click()\n",
    "\n",
    "\n",
    "    num_books = len(driver.find_elements_by_class_name(\"Yr5TG\"))\n",
    "    page=2\n",
    "    num_image=0\n",
    "\n",
    "# We tell the program how many pages to go through here. <3\n",
    "    \n",
    "    while (page < 7):\n",
    "\n",
    "    \n",
    " # This counts the number of books and the variable count is\n",
    " # counting the iteration number.\n",
    "    \n",
    " # THe program will only do this once the crawler\n",
    " # has arrived to a new page.\n",
    "    \n",
    "        for i in range(1,num_books):\n",
    "        \n",
    "            k='{}'.format(i) \n",
    "        \n",
    "        # Check to see if the xpath exists.\n",
    "        \n",
    "            if (hasXpath(f'//*[@id=\"rso\"]/div[{k}]/div[2]/a/h3')):\n",
    "            \n",
    "            # We find the title here.\n",
    "            \n",
    "                title=driver.find_element_by_xpath(f'//*[@id=\"rso\"]/div[{k}]/div[2]/a/h3').text\n",
    "        \n",
    "            # We are trying to extract the book names here.\n",
    "            # Why? Because sometimes, the word is associated with\n",
    "            # a book name, and it just iterates through that a lot,\n",
    "            # in which case it usually holds not a lot of information.\n",
    "\n",
    "            \n",
    "            # But first, we need to be determine if the book has a semi-colon.\n",
    "            \n",
    "            # We use the variable c to keep a counter of the number of book\n",
    "            # titles that we will be storing.\n",
    "            \n",
    "                if ':' in title:\n",
    "                \n",
    "                    first = title.rsplit(':')[0]\n",
    "                \n",
    "                    sec = title.split(':')[1]\n",
    "                \n",
    "                    book_name.append(first)\n",
    "                    book_name.append(sec)\n",
    "                \n",
    "                    c+=2\n",
    "                \n",
    "                    book_name[c-1]=book_name[c-1].lower()\n",
    "                    book_name[c-2]=book_name[c-2].lower()\n",
    "                \n",
    "                for i in range(num_books-1):\n",
    "                \n",
    "                    print(book_name[i])\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    book_name.append(title)\n",
    "                    c+=1\n",
    "                    book_name[c-1]=book_name[c-1].lower()\n",
    "\n",
    "            \n",
    "    \n",
    "    # Book count will keep track of which book we are on on the\n",
    "    # page, and elems will contain all of the links to the books\n",
    "    # that we will use to enter each book.\n",
    "    \n",
    "        book_count=0\n",
    "        elems=driver.find_elements_by_xpath(\"//*[contains(@href,'https://books.google.ca/books?id=')]\") \n",
    "\n",
    "\n",
    "\n",
    "        sleep(2)\n",
    "\n",
    "\n",
    "    # Then, the program will loop through all of the found books here.\n",
    "    \n",
    "        for i in range((num_books-1)):\n",
    "        \n",
    "            elems=driver.find_elements_by_xpath(\"//*[contains(@href,'https://books.google.ca/books?id=')]\") \n",
    "        \n",
    "            elems[book_count].click()\n",
    "        \n",
    "            book_count+=2\n",
    "            print(book_count)\n",
    "\n",
    "            sleep(3)\n",
    "\n",
    "\n",
    "        # Sometimes, google books isn't formatted in the\n",
    "        # way that the book is in the form of a pop up.\n",
    "        \n",
    "        # So, to account for this, we see if the website \n",
    "        # has more than one frame.\n",
    "        \n",
    "        # If it does, we switch the reference frame to the pop\n",
    "        # up, else we keep it as is.\n",
    "        \n",
    "            iframes = driver.find_elements_by_tag_name(\"iframe\")\n",
    "        \n",
    "            if (hasClass(\"fuHCCc\")):\n",
    "    \n",
    "                driver.switch_to.frame(\"s7Z8Jb\")\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        # Next, we check if the website contains the \"View all\"\n",
    "        # button that helps us find the specific parts of the text\n",
    "        # that contain the word that we are seeking to understand.\n",
    "        \n",
    "        # If it doesn't contain it, it will simply take a screenshot,\n",
    "        # then exit.\n",
    "        \n",
    "            sleep(3)\n",
    "        \n",
    "        \n",
    "            screen_shot_break.append(num_image)\n",
    "        \n",
    "            if (hasXpath('span.search-bar-link:nth-child(6)')):\n",
    "            \n",
    "                try:\n",
    "                    driver.find_element_by_css_selector('span.search-bar-link:nth-child(6)').click()\n",
    "                \n",
    "                    curr_height=0\n",
    "                \n",
    "               \n",
    "                    if (hasClass(\"scroll-background\")):\n",
    "                    \n",
    "                        driver.execute_script(\"arguments[0].style.transform='scale(2.15)';\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "                    #driver.execute_script(\"arguments[0].style_zoom='zoom 5000%\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "                    \n",
    "                        elem = driver.find_element_by_class_name(\"scroll-background\")\n",
    "                    \n",
    "    \n",
    "                        total_height = float(elem.get_attribute(\"style\")[22:-3])\n",
    "                    \n",
    "                        sleep(2)\n",
    "                \n",
    "                    # While we have not reached the end of the page,\n",
    "                    # we will screenshot all of the relevant sections\n",
    "                    # of the book that contain the word.\n",
    "                    \n",
    "                    # This loop will continue to scroll down until we have \n",
    "                    # reached the end of the page.\n",
    "                    \n",
    "                    # I've noticed that sometimes, a book can have too many pages. This \n",
    "                    # might skew our representation of how the text network analysis looks.\n",
    "                    \n",
    "                    # So, I am going to put a counter, and only allow\n",
    "                    # a maximum of 20 screenshots per book\n",
    "                    \n",
    "                        screenshot_count=0\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                        while curr_height < total_height and screenshot_count<10:\n",
    "                        \n",
    "                        # Give the program some time to load the book.\n",
    "                        \n",
    "                            sleep(5)\n",
    "\n",
    "                        # We save the screenshots and crop them.\n",
    "                        \n",
    "                        # zoom in here.\n",
    "                            driver.save_screenshot(f\"{num_image}.png\")\n",
    "                        \n",
    "                            img = Image.open(f\"{num_image}.png\")\n",
    "                            area = (100, 140, 1200, 950)\n",
    "                            img = img.crop(area)\n",
    "                            img.save(f\"{num_image}.png\")\n",
    "           \n",
    "                            driver.execute_script(\"arguments[0].scrollBy(0, 250)\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "   \n",
    "                            curr_height += driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "                        \n",
    "                            screenshot_count+=1\n",
    "                            num_image+=1\n",
    "            \n",
    "                    else:\n",
    "                    \n",
    "                    #driver.execute_script(\"document.body.style.zoom='200%'\")\n",
    "                        driver.executeScript(\"arguments[0].style.transform='scale(0.9)'\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "                    #driver.execute_script(\"arguments[0].style_zoom='zoom 200%\",driver.find_element_by_class_name(\"overflow-scrolling\"))\n",
    "                        driver.save_screenshot(f\"{num_image}.png\")\n",
    "                        img = Image.open(f\"{num_image}.png\")\n",
    "                        area = (340, 140, 900, 950)\n",
    "                        img = img.crop(area)\n",
    "                        img.save(f\"{num_image}.png\")\n",
    "           \n",
    "                        num_image+=1\n",
    "    \n",
    "#______________________________________________________________________    \n",
    "    \n",
    "                    sleep(2)\n",
    "\n",
    "    \n",
    "                    driver.execute_script(\"window.history.go(-1)\")\n",
    "                    driver.switch_to.default_content()\n",
    "        \n",
    "                    sleep(3)\n",
    "            \n",
    "                except WebDriverException:\n",
    "                \n",
    "                    driver.save_screenshot(f\"{num_image}.png\")\n",
    "                    img = Image.open(f\"{num_image}.png\")\n",
    "                    area = (340, 140, 900, 950)\n",
    "                    img = img.crop(area)\n",
    "                    img.save(f\"{num_image}.png\")\n",
    "                \n",
    "                    num_image+=1\n",
    "                \n",
    "                    driver.execute_script(\"window.history.go(-1)\")\n",
    "                    driver.switch_to.default_content()\n",
    "                \n",
    "                    sleep(3)\n",
    "            else:\n",
    "            \n",
    "            #sleep(3)\n",
    "            \n",
    "            #action.key_down(Keys.COMMAND).send_keys('+').key_up(Keys.COMMAND).perform()\n",
    "            #driver.execute_script(\"arguments[0].style.transform='scale(2.15)';\",driver.find_element_by_class_name('about_content'))\n",
    "            #driver.execute_script(\"document.body.style.zoom = '30%'\");\n",
    "            \n",
    "                driver.save_screenshot(f\"{num_image}.png\")\n",
    "                img = Image.open(f\"{num_image}.png\")\n",
    "                area = (340, 140, 900, 950)\n",
    "                img = img.crop(area)\n",
    "                img.save(f\"{num_image}.png\")\n",
    "           \n",
    "            \n",
    "                num_image+=1\n",
    "            \n",
    "                driver.execute_script(\"window.history.go(-1)\")\n",
    "                driver.switch_to.default_content()\n",
    "            \n",
    "                sleep(3)\n",
    "    \n",
    "    \n",
    "        screen_shot_break.append(num_image)\n",
    "        num_books = len(driver.find_elements_by_class_name(\"Yr5TG\"))\n",
    "        page += 1\n",
    "        select=f\".AaVjTc > tbody:nth-child(1) > tr:nth-child(1) > td:nth-child({page}) > a:nth-child(1)\"\n",
    "\n",
    "        decade_count.append()\n",
    "        driver.find_element_by_css_selector(select).click() \n",
    "    \n",
    "    imagelist = []\n",
    "# adding to doc  \n",
    "    for i in range(num_image):\n",
    "        tmp=Image.open(f'{i}.png')\n",
    "        con=tmp.convert('RGB')\n",
    "        imagelist.append(con)\n",
    "\n",
    "    con.save(f'mergedImages{decade_count}.pdf',save_all=True, \n",
    "    append_images=imagelist)\n",
    "\n",
    "\n",
    "    tmp=[str(i) for i in str(curr_year)]\n",
    "\n",
    "    pre_start  = \"\".join(tmp[2:])\n",
    "\n",
    "    pre_start = int(pre_start)\n",
    "\n",
    "    suf_start  = \"\".join(tmp[:2])\n",
    "\n",
    "    suf_start = int(pre_start)\n",
    "\n",
    "    if (suf_start == 0):\n",
    "        pre_start +=1\n",
    "        curr_year = pre_start*100\n",
    "        suf_start = 0\n",
    "    else:\n",
    "        \n",
    "        curr_year=pre_start*100+suf_start\n",
    "        suf_start +=10\n",
    "\n",
    "    decade_count +=1\n",
    "    decade_list.append(curr_year)\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
