# Google-Books-Text-Network-Analysis

I was motivated to make this because I am deeply saddened by how many books are created and don't get to the people that would highly benefit from reading it. We only have so much time to find and read new books, and, as such, this project seeks to gather some insight on any given topic by understanding the context in which it was used in past decades.  In order to do this, I give the user the option to select a word of choice, and a set span of dates that they would like to gain insight from.  I created a web crawler to then go through all of the books that contains the word of choice, and screenshot those pages.  After this, the program will compile the images into a pdf.  The user will then have to extract the text from the images (https://ocrgeek.com/) and then send the returned text file to the program.  Before creating the text network, I will pre-process the text, which will involve getting rid of words that are not associated to the book (i.e. We couldn't make an image for this result. Click to view the whole p appears at the top of the text box), and then go on to get rid of symbols, lower case the words, lemmatize, and spell-check, in that order.  The program will then take this text and build an adjacency list that composes of all of the words that are close to the selected word.  If the word is right next to the chosen word, I will create an edge with weight 5. If it is 2 words away from the word of choice, I will create an edge with weight 4. I will continue to do this until the words are 5 words apart, to which then the edge weight will be 1. If the word has already been associated with the word of choice, it will simply increment the weight number.  
This then will be displayed using the module networkX.

The final result will look something like this.
![Screen Shot 2021-12-01 at 7 32 30 PM](https://user-images.githubusercontent.com/76268134/144347799-86c7eb02-a940-42f9-9df4-03cb2ba5bab8.png)

